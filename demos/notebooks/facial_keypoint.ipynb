{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dab455",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "os.environ[\"TORCH_HOME\"] = \"/media/hdd/Datasets/\"\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import zeus\n",
    "from zeus.callbacks import (EarlyStopping, GradientClipping, PlotLoss,\n",
    "                            TensorBoardLogger)\n",
    "from zeus.datasets import ImageDataset\n",
    "from zeus.metrics import LabelSmoothingCrossEntropy, root_mean_squared_error\n",
    "from zeus.utils.model_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5b1a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Defining\n",
    "\n",
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf8c26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = \"/media/hdd/Datasets/faceKeypoint/\"\n",
    "MODEL_PATH = \"./models/\"\n",
    "MODEL_NAME = os.path.basename(\"face.pt\")\n",
    "TRAIN_BATCH_SIZE = 140\n",
    "VALID_BATCH_SIZE = 140\n",
    "IMAGE_SIZE = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf770c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "class FacialKeypointDataset(Dataset):\n",
    "    def __init__(self, csv_file, train=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.category_names = [\n",
    "            \"left_eye_center_x\",\n",
    "            \"left_eye_center_y\",\n",
    "            \"right_eye_center_x\",\n",
    "            \"right_eye_center_y\",\n",
    "            \"left_eye_inner_corner_x\",\n",
    "            \"left_eye_inner_corner_y\",\n",
    "            \"left_eye_outer_corner_x\",\n",
    "            \"left_eye_outer_corner_y\",\n",
    "            \"right_eye_inner_corner_x\",\n",
    "            \"right_eye_inner_corner_y\",\n",
    "            \"right_eye_outer_corner_x\",\n",
    "            \"right_eye_outer_corner_y\",\n",
    "            \"left_eyebrow_inner_end_x\",\n",
    "            \"left_eyebrow_inner_end_y\",\n",
    "            \"left_eyebrow_outer_end_x\",\n",
    "            \"left_eyebrow_outer_end_y\",\n",
    "            \"right_eyebrow_inner_end_x\",\n",
    "            \"right_eyebrow_inner_end_y\",\n",
    "            \"right_eyebrow_outer_end_x\",\n",
    "            \"right_eyebrow_outer_end_y\",\n",
    "            \"nose_tip_x\",\n",
    "            \"nose_tip_y\",\n",
    "            \"mouth_left_corner_x\",\n",
    "            \"mouth_left_corner_y\",\n",
    "            \"mouth_right_corner_x\",\n",
    "            \"mouth_right_corner_y\",\n",
    "            \"mouth_center_top_lip_x\",\n",
    "            \"mouth_center_top_lip_y\",\n",
    "            \"mouth_center_bottom_lip_x\",\n",
    "            \"mouth_center_bottom_lip_y\",\n",
    "        ]\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            # image = np.array(self.data.iloc[index, 30].split()).astype(np.float32)\n",
    "            image = np.array(self.data.iloc[index, 30].split(), dtype=np.float32)\n",
    "            labels = np.array(self.data.iloc[index, :30].tolist())\n",
    "            labels[np.isnan(labels)] = -1\n",
    "        else:\n",
    "            image = np.array(self.data.iloc[index, 1].split()).astype(np.float32)\n",
    "            labels = np.zeros(30)\n",
    "\n",
    "        ignore_indices = labels == -1\n",
    "        labels = labels.reshape(15, 2)\n",
    "\n",
    "        if self.transform:\n",
    "            image = np.repeat(image.reshape(96, 96, 1), 3, 2).astype(np.uint8)\n",
    "            augmentations = self.transform(image=image, keypoints=labels)\n",
    "            image = augmentations[\"image\"]\n",
    "            labels = augmentations[\"keypoints\"]\n",
    "\n",
    "        labels = np.array(labels).reshape(-1)\n",
    "        labels[ignore_indices] = -1\n",
    "\n",
    "        return {\"image\": image, \"targets\": labels.astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada29b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "class Model(zeus.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = EfficientNet.from_pretrained(\"efficientnet-b0\").cuda()\n",
    "        self.model._fc = nn.Linear(1280, 30)\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        accuracy = root_mean_squared_error(targets, outputs)\n",
    "        return {\"rmse\": float(accuracy), \"epoch\": self.current_epoch}\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        return opt\n",
    "\n",
    "    def forward(self, image, targets=None):\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        outputs = self.model(image)\n",
    "        outputs[targets == -1] = -1\n",
    "\n",
    "        if targets is not None:\n",
    "            # targets = targets.float().unsqueeze(1)\n",
    "            loss = nn.MSELoss(reduction=\"sum\")(outputs, targets)\n",
    "            metrics = self.monitor_metrics(outputs, targets)\n",
    "            return outputs, loss, metrics\n",
    "        return outputs, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caf40a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "## Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=IMAGE_SIZE, height=IMAGE_SIZE),\n",
    "        A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT, p=0.8),\n",
    "        A.IAAAffine(shear=15, scale=1.0, mode=\"constant\", p=0.2),\n",
    "        A.RandomBrightnessContrast(contrast_limit=0.5, brightness_limit=0.5, p=0.2),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.GaussNoise(p=0.8),\n",
    "                A.CLAHE(p=0.8),\n",
    "                A.ImageCompression(p=0.8),\n",
    "                A.RandomGamma(p=0.8),\n",
    "                A.Posterize(p=0.8),\n",
    "                A.Blur(p=0.8),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.GaussNoise(p=0.8),\n",
    "                A.CLAHE(p=0.8),\n",
    "                A.ImageCompression(p=0.8),\n",
    "                A.RandomGamma(p=0.8),\n",
    "                A.Posterize(p=0.8),\n",
    "                A.Blur(p=0.8),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=0,\n",
    "            p=0.2,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=[0.4897, 0.4897, 0.4897],\n",
    "            std=[0.2330, 0.2330, 0.2330],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False),\n",
    ")\n",
    "\n",
    "valid_aug = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=96, width=96),\n",
    "        A.Normalize(\n",
    "            mean=[0.4897, 0.4897, 0.4897],\n",
    "            std=[0.2330, 0.2330, 0.2330],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ee102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the trains\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df = pd.read_csv(Path(INPUT_PATH)/\"training.csv\")\n",
    "# df[\"Image\"] = df[\"Image\"].astype(str)\n",
    "# df_tr, df_ts = train_test_split(df, test_size=.3)\n",
    "# df_tr.to_csv(Path(INPUT_PATH)/\"train_split.csv\")\n",
    "# df_ts.to_csv(Path(INPUT_PATH)/\"test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "train_ds = FacialKeypointDataset(Path(INPUT_PATH) / \"training.csv\", transform=train_aug)\n",
    "valid_ds = FacialKeypointDataset(\n",
    "    Path(INPUT_PATH) / \"test.csv\", train=False, transform=valid_aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfe654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paramas\n",
    "model = Model()\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"valid_loss\",\n",
    "    model_path=os.path.join(MODEL_PATH, MODEL_NAME + \".bin\"),\n",
    "    patience=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "tb = TensorBoardLogger()\n",
    "grc = GradientClipping(5)\n",
    "pl = PlotLoss(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model, showtable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    valid_dataset=valid_ds,\n",
    "    train_bs=TRAIN_BATCH_SIZE,\n",
    "    valid_bs=TRAIN_BATCH_SIZE,\n",
    "    device=\"cuda\",\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[grc, pl, tb],\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c921dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
